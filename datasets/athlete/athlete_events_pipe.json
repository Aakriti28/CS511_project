{
    "Input": [
        {
            "method": "load_dataset",
            "input": {
                "sep": ","
            },
            "input_dask": {
                "sep": ",",
                "assume_missing": "True",
                "dtype": "object"
            },
            "input_koalas": {
                "sep": ",",
                "assume_missing": "True"
            },
            "input_vaex1": {
                "sep": ",",
                "low_memory": "False"
            },
            "input_vaex": {
                "lazy": true
            }
        },
        {
            "method": "force_execution",
            "input": {}
        }
    ],
    "EDA": [
        {
            "method": "get_columns",
            "input": {}
        },
        {
            "method": "locate_null_values",
            "input": {
                "column": "all"
            }
        },
        {
            "method": "sort",
            "input": {
                "columns": [
                    "Year"
                ]
            },
            "input_dask": {
                "columns": [
                    "Year"
                ],
                "cast": {
                    "Year": "int64"
                }
            }
        },
        {
            "method": "query",
            "input": {
                "query": "Year >= 1960 & Season == 'Summer'"
            },
            "input_rapids": {
                "query": "(Year >= 1960 and Season == 'Summer')"
            },
            "input_datatable": {
                "query": "((dt.f.Year >= 1960) & (dt.f.Season == 'Summer'))"
            },
            "input_polars": {
                "query": "(pl.col('Year') >= 1960) & (pl.col('Season') == 'Summer')",
                "req_compile": [
                    "query"
                ],
                "extra_commands": [
                    "import polars as pl"
                ]
            },
            "input_spark": {
                "query": "(fn.col('Year') >= 1960) & (fn.col('Season') == 'Summer')",
                "req_compile": [
                    "query"
                ],
                "extra_commands": [
                    "import pyspark.sql.functions as fn"
                ]
            },
            "input_pyspark_pandas": {
                "query": "('Year' >= 1960) and ('Season' == 'Summer')"
            },
            "input_vaex": {
                "query": "Year >= 1960 and Season == 'Summer'"
            }
        },
        {
            "method": "force_execution",
            "input": {}
        }
    ],
    "data_transformation": [
        {
            "method": "join",
            "input": {
                "other": "noc_region",
                "left_on": "NOC",
                "right_on": "NOC",
                "how": "left",
                "req_compile": [
                    "other"
                ],
                "extra_commands": [
                    "import pandas as pd",
                    "noc_region=pd.read_csv('datasets/athlete/noc_regions.csv')"
                ]
            },
            "input_datatable": {
                "other": "noc_region",
                "left_on": "NOC",
                "right_on": "NOC",
                "how": "left",
                "req_compile": [
                    "other"
                ],
                "extra_commands": [
                    "import pandas as pd",
                    "noc_region=pd.read_csv('datasets/athlete/noc_regions.csv')",
                    "import datatable as dt",
                    "noc_region=dt.Frame(noc_region)"
                ]
            },
            "input_pyspark_pandas": {
                "other": "noc_region",
                "left_on": [
                    "NOC"
                ],
                "right_on": [
                    "NOC"
                ],
                "how": "left",
                "req_compile": [
                    "other"
                ],
                "extra_commands": [
                    "import pyspark.pandas as pd",
                    "noc_region=pd.read_csv('datasets/athlete/noc_regions.csv')"
                ]
            },
            "input_dask": {
                "other": "noc_region",
                "left_on": "NOC",
                "right_on": "NOC",
                "how": "left",
                "req_compile": [
                    "other"
                ],
                "extra_commands": [
                    "import pandas as pd",
                    "noc_region=pd.read_csv('datasets/athlete/noc_regions.csv')",
                    "import dask.dataframe as dd",
                    "noc_region=dd.from_pandas(noc_region, npartitions=1)"
                ]
            },
            "input_modin_dask": {
                "other": "noc_region",
                "left_on": "NOC",
                "right_on": "NOC",
                "how": "left",
                "req_compile": [
                    "other"
                ],
                "extra_commands": [
                    "import pandas as pd",
                    "noc_region=pd.read_csv('datasets/athlete/noc_regions.csv', dtype='object')",
                    "import modin.pandas as mpd",
                    "noc_region=mpd.DataFrame(noc_region)"
                ]
            },
            "input_modin_ray": {
                "other": "noc_region",
                "left_on": "NOC",
                "right_on": "NOC",
                "how": "left",
                "req_compile": [
                    "other"
                ],
                "extra_commands": [
                    "import pandas as pd",
                    "noc_region=pd.read_csv('datasets/athlete/noc_regions.csv', dtype='object')",
                    "import modin.pandas as mpd",
                    "noc_region=mpd.DataFrame(noc_region)"
                ]
            },
            "input_vaex": {
                "other": "noc_region",
                "left_on": "NOC",
                "right_on": "NOC",
                "how": "left",
                "req_compile": [
                    "other"
                ],
                "extra_commands": [
                    "import pandas as pd",
                    "noc_region=pd.read_csv('datasets/athlete/noc_regions.csv', sep=',', header=0)",
                    "import vaex",
                    "noc_region=vaex.from_pandas(noc_region)"
                ]
            },
            "input_rapids": {
                "other": "noc_region",
                "left_on": "NOC",
                "right_on": "NOC",
                "how": "left",
                "req_compile": [
                    "other"
                ],
                "extra_commands": [
                    "import pandas as pd",
                    "import cudf",
                    "noc_region=cudf.from_pandas(pd.read_csv('datasets/athlete/noc_regions.csv', sep=','))"
                ]
            },
            "input_polars": {
                "other": "noc_region",
                "left_on": "NOC",
                "right_on": "NOC",
                "how": "left",
                "req_compile": [
                    "other"
                ],
                "extra_commands": [
                    "import pandas as pd",
                    "noc_region=pd.read_csv('datasets/athlete/noc_regions.csv', dtype='object')",
                    "import polars as pl",
                    "noc_region=pl.from_pandas(noc_region).lazy()"
                ]
            },
            "input_spark": {
                "other": "noc_region",
                "left_on": [
                    "NOC"
                ],
                "right_on": [
                    "NOC"
                ],
                "how": "left",
                "req_compile": [
                    "other"
                ],
                "extra_commands": [
                    "from pyspark.sql import DataFrame, SparkSession",
                    "sparkSession=SparkSession.builder.getOrCreate()",
                    "import pandas as pd",
                    "noc_region=pd.read_csv('datasets/athlete/noc_regions.csv')",
                    "from pyspark.sql.types import *",
                    "schema = StructType([StructField('NOC', StringType(), True), StructField('region', StringType(), True), StructField('notes', StringType(), True)])",
                    "noc_region=sparkSession.createDataFrame(noc_region, schema=schema)",
                    "noc_region.persist()"
                ]
            }
        },
        {
            "method": "delete_columns",
            "input": {
                "columns": [
                    "notes"
                ]
            }
        },
        {
            "method": "rename_columns",
            "input": {
                "columns": {
                    "region": "Country"
                }
            }
        },
        {
            "method": "delete_columns",
            "input": {
                "columns": [
                    "Team"
                ]
            }
        },
        {
            "method": "calc_column",
            "input": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Singapore' if x[1] == 'SGP' else x[0]",
                "apply": true
            },
            "input_vaex": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x, y: 'Singapore' if y == 'SGP' else x"
            },
            "input_spark": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x, y: 'Singapore' if y == 'SGP' else x",
                "apply": true
            },
            "input_polars": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Singapore' if x['NOC'] == 'SGP' else x['Country']",
                "return_dtype": "pl.Utf8",
                "apply": true
            },
            "input_rapids": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Singapore' if x['NOC'] == 'SGP' else x['Country']",
                "apply": true
            },
            "input_pyspark_pandas": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Singapore' if x['NOC'].to_cupy()[0][0] == 'SGP' else x['Country']",
                "apply": true
            }
        },
        {
            "method": "calc_column",
            "input": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Refugee Olympic Athletes' if x[1] == 'ROT' else x[0]",
                "apply": true
            },
            "input_vaex": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x, y: 'Refugee Olympic Athletes' if y == 'ROT' else x"
            },
            "input_spark": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x, y: 'Refugee Olympic Athletes' if y == 'ROT' else x",
                "apply": true
            },
            "input_polars": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Refugee Olympic Athletes' if x['NOC'] == 'ROT' else x['Country']",
                "return_dtype": "pl.Utf8",
                "apply": true
            },
            "input_pyspark_pandas": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Refugee Olympic Athletes' if x['NOC'] == 'ROT' else x['Country']",
                "apply": true
            }
        },
        {
            "method": "calc_column",
            "input": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Unknown' if x[1] == 'UNK' else x[0]",
                "apply": true
            },
            "input_vaex": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x, y: 'Unknown' if y == 'UNK' else x"
            },
            "input_spark": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x, y: 'Unknown' if y == 'UNK' else x",
                "apply": true
            },
            "input_polars": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Unknown' if x['NOC'] == 'UNK' else x['Country']",
                "return_dtype": "pl.Utf8",
                "apply": true
            },
            "input_pyspark_pandas": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Unknown' if x['NOC'] == 'UNK' else x['Country']",
                "apply": true
            }
        },
        {
            "method": "calc_column",
            "input": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Tuvalu' if x[1] == 'TUV' else x[0]",
                "apply": true
            },
            "input_vaex": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x, y: 'Tuvalu' if y == 'TUV' else x"
            },
            "input_spark": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x, y: 'Tuvalu' if y == 'TUV' else x",
                "apply": true
            },
            "input_polars": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Tuvalu' if x['NOC'] == 'TUV' else x['Country']",
                "return_dtype": "pl.Utf8",
                "apply": true
            },
            "input_pyspark_pandas": {
                "col_name": "Country",
                "columns": [
                    "Country",
                    "NOC"
                ],
                "f": "lambda x: 'Tuvalu' if x['NOC'] == 'TUV' else x['Country']",
                "apply": true
            }
        },
        {
            "method": "rename_columns",
            "input": {
                "columns": {
                    "Country": "Team"
                }
            }
        },
        {
            "method": "cast_columns_types",
            "input": {
                "dtypes": {
                    "Team": "str"
                }
            },
            "input_polars": {
                "dtypes": {
                    "Team": "polars.Utf8"
                },
                "req_compile": [
                    "dtypes"
                ],
                "extra_commands": [
                    "import polars"
                ]
            },
            "input_spark": {
                "dtypes": {
                    "Team": "T.StringType()"
                },
                "req_compile": [
                    "dtypes"
                ],
                "extra_commands": [
                    "import pyspark.sql.types as T"
                ]
            },
            "input_vaex": {
                "dtypes": {
                    "Team": "string"
                }
            }
        },
        {
            "method": "calc_column",
            "input": {
                "col_name": "Medal_Won",
                "columns": [
                    "Medal"
                ],
                "f": "lambda x: 0 if x[0] == 'DNW' else 1",
                "apply": true
            },
            "input_rapids":{
                "col_name": "Medal_Won",
                "columns": [
                    "Medal"
                ],
                "f": "lambda x: 0 if x['Medal'] == 'DNW' else 1",
                "apply": true
            },
            "input_vaex": {
                "col_name": "Medal_Won",
                "columns": [
                    "Medal"
                ],
                "f": "lambda x: 0 if x == 'DNW' else 1"
            },
            "input_polars": {
                "col_name": "Medal_Won",
                "columns": [
                    "Medal"
                ],
                "f": "lambda x: 0 if x == 'DNW' else 1",
                "return_dtype": "pl.Int64",
                "apply": true
            },
            "input_spark": {
                "col_name": "Medal_Won",
                "columns": [
                    "Medal"
                ],
                "f": "lambda x: 0 if x == 'DNW' else 1",
                "apply": true
            },
            "input_pyspark_pandas": {
                "col_name": "Medal_Won",
                "columns": [
                    "Medal"
                ],
                "f": "lambda x: 0 if x['Medal'] == 'DNW' else 1",
                "apply": true
            }
        },
        {
            "method": "groupby",
            "input": {
                "columns": [
                    "Team",
                    "Name",
                    "Sport"
                ],
                "f": {
                    "Medal_Won": "sum"
                }
            },
            "input_datatable": {
                "columns": [
                    "Team",
                    "Name",
                    "Sport"
                ],
                "f": "dt.sum(dt.f['Medal_Won'])"
            },
            "input_polars": {
                "columns": [
                    "Team",
                    "Name",
                    "Sport"
                ],
                "f": "pl.sum(pl.col('Medal_Won'))"
            }
        },
        {
            "method": "groupby",
            "input": {
                "columns": [
                    "Team",
                    "Name",
                    "Sport"
                ],
                "f": {
                    "NOC": "count"
                }
            },
            "input_datatable": {
                "columns": [
                    "Team",
                    "Name",
                    "Sport"
                ],
                "f": "dt.count(dt.f['NOC'])"
            },
            "input_polars": {
                "columns": [
                    "Team",
                    "Name",
                    "Sport"
                ],
                "f": "pl.count(pl.col('NOC'))"
            }
        },
        {
            "method": "force_execution",
            "input": {}
        }
    ],
    "data_cleaning": [
        {
            "method": "drop_duplicates",
            "input": {}
        },
        {
            "method": "fill_nan",
            "input": {
                "columns": [
                    "Medal"
                ],
                "value": "DNW"
            }
        },
        {
            "method": "replace",
            "input": {
                "columns": [
                    "City"
                ],
                "to_replace": "Athina",
                "value": "Athens",
                "regex": false
            },
            "input_polars": {
                "columns": [
                    "City"
                ],
                "to_replace": "Athina",
                "value": "Athens",
                "regex": false,
                "return_dtype": "pl.Utf8"
            }
        },
        {
            "method": "replace",
            "input": {
                "columns": [
                    "City"
                ],
                "to_replace": "Moskva",
                "value": "Moscow",
                "regex": false
            },
            "input_polars": {
                "columns": [
                    "City"
                ],
                "to_replace": "Moskva",
                "value": "Moscow",
                "regex": false,
                "return_dtype": "pl.Utf8"
            }
        },
        {
            "method": "force_execution",
            "input": {}
        }
    ],
    "output": [
        {
            "method": "to_csv",
            "input": {
                "sep": ","
            },
            "input_datatable": {},
            "input_vaex": {},
            "input_polars": {}
        }
    ]
}
